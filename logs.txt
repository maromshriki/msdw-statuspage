
==> Audit <==
|---------|----------------------------|----------|--------|---------|---------------------|---------------------|
| Command |            Args            | Profile  |  User  | Version |     Start Time      |      End Time       |
|---------|----------------------------|----------|--------|---------|---------------------|---------------------|
| start   |                            | minikube | ubuntu | v1.36.0 | 04 Sep 25 20:15 UTC | 04 Sep 25 20:16 UTC |
| start   |                            | minikube | ubuntu | v1.36.0 | 07 Sep 25 09:48 UTC |                     |
| start   |                            | minikube | ubuntu | v1.36.0 | 07 Sep 25 09:54 UTC |                     |
| addons  | enable storage-provisioner | minikube | ubuntu | v1.36.0 | 07 Sep 25 09:57 UTC |                     |
|---------|----------------------------|----------|--------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2025/09/07 09:54:48
Running on machine: ip-10-0-1-29
Binary: Built with gc go1.24.0 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0907 09:54:48.721244   14948 out.go:345] Setting OutFile to fd 1 ...
I0907 09:54:48.721368   14948 out.go:392] TERM=xterm,COLORTERM=, which probably does not support color
I0907 09:54:48.721374   14948 out.go:358] Setting ErrFile to fd 2...
I0907 09:54:48.721379   14948 out.go:392] TERM=xterm,COLORTERM=, which probably does not support color
I0907 09:54:48.721585   14948 root.go:338] Updating PATH: /home/ubuntu/.minikube/bin
W0907 09:54:48.721686   14948 root.go:314] Error reading config file at /home/ubuntu/.minikube/config/config.json: open /home/ubuntu/.minikube/config/config.json: no such file or directory
I0907 09:54:48.721908   14948 out.go:352] Setting JSON to false
I0907 09:54:48.722768   14948 start.go:130] hostinfo: {"hostname":"ip-10-0-1-29","uptime":1322,"bootTime":1757237567,"procs":159,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"24.04","kernelVersion":"6.14.0-1012-aws","kernelArch":"x86_64","virtualizationSystem":"xen","virtualizationRole":"guest","hostId":"ec242f0b-4769-bd23-4181-ab00219e7c3f"}
I0907 09:54:48.722875   14948 start.go:140] virtualization: xen guest
I0907 09:54:48.726050   14948 out.go:177] * minikube v1.36.0 on Ubuntu 24.04 (xen/amd64)
I0907 09:54:48.728519   14948 notify.go:220] Checking for updates...
I0907 09:54:48.728870   14948 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0907 09:54:48.728996   14948 driver.go:404] Setting default libvirt URI to qemu:///system
I0907 09:54:48.756574   14948 docker.go:123] docker version: linux-28.3.3:Docker Engine - Community
I0907 09:54:48.756643   14948 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0907 09:54:48.818913   14948 info.go:266] docker info: {ID:be95c06d-3b8f-49e3-9448-c263ea69dae3 Containers:5 ContainersRunning:1 ContainersPaused:0 ContainersStopped:4 Images:18 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:36 OomKillDisable:false NGoroutines:53 SystemTime:2025-09-07 09:54:48.808001675 +0000 UTC LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.14.0-1012-aws OperatingSystem:Ubuntu 24.04.3 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:16766861312 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ip-10-0-1-29 Labels:[] ExperimentalBuild:false ServerVersion:28.3.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:05044ec0a9a75232cad458027ca83437aae3f4da Expected:} RuncCommit:{ID:v1.2.5-0-g59923ef Expected:} InitCommit:{ID:de40ad0 Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.26.1] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.39.1]] Warnings:<nil>}}
I0907 09:54:48.819005   14948 docker.go:318] overlay module found
I0907 09:54:48.821715   14948 out.go:177] * Using the docker driver based on existing profile
I0907 09:54:48.824086   14948 start.go:304] selected driver: docker
I0907 09:54:48.824095   14948 start.go:908] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0907 09:54:48.824169   14948 start.go:919] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0907 09:54:48.824262   14948 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0907 09:54:48.889215   14948 info.go:266] docker info: {ID:be95c06d-3b8f-49e3-9448-c263ea69dae3 Containers:5 ContainersRunning:1 ContainersPaused:0 ContainersStopped:4 Images:18 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:36 OomKillDisable:false NGoroutines:53 SystemTime:2025-09-07 09:54:48.878646221 +0000 UTC LoggingDriver:json-file CgroupDriver:systemd NEventsListener:0 KernelVersion:6.14.0-1012-aws OperatingSystem:Ubuntu 24.04.3 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[::1/128 127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:4 MemTotal:16766861312 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:ip-10-0-1-29 Labels:[] ExperimentalBuild:false ServerVersion:28.3.3 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:05044ec0a9a75232cad458027ca83437aae3f4da Expected:} RuncCommit:{ID:v1.2.5-0-g59923ef Expected:} InitCommit:{ID:de40ad0 Expected:} SecurityOptions:[name=apparmor name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:<nil> ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.26.1] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.39.1]] Warnings:<nil>}}
I0907 09:54:48.889755   14948 cni.go:84] Creating CNI manager for ""
I0907 09:54:48.889829   14948 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0907 09:54:48.889886   14948 start.go:347] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0907 09:54:48.894028   14948 out.go:177] * Starting "minikube" primary control-plane node in "minikube" cluster
I0907 09:54:48.896294   14948 cache.go:121] Beginning downloading kic base image for docker with docker
I0907 09:54:48.898629   14948 out.go:177] * Pulling base image v0.0.47 ...
I0907 09:54:48.901483   14948 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0907 09:54:48.901513   14948 preload.go:146] Found local preload: /home/ubuntu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4
I0907 09:54:48.901520   14948 cache.go:56] Caching tarball of preloaded images
I0907 09:54:48.901596   14948 image.go:81] Checking for gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon
I0907 09:54:48.901623   14948 preload.go:172] Found /home/ubuntu/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0907 09:54:48.901635   14948 cache.go:59] Finished verifying existence of preloaded tar for v1.33.1 on docker
I0907 09:54:48.901724   14948 profile.go:143] Saving config to /home/ubuntu/.minikube/profiles/minikube/config.json ...
I0907 09:54:48.929518   14948 image.go:100] Found gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon, skipping pull
I0907 09:54:48.929535   14948 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b exists in daemon, skipping load
I0907 09:54:48.929561   14948 cache.go:230] Successfully downloaded all kic artifacts
I0907 09:54:48.929579   14948 start.go:360] acquireMachinesLock for minikube: {Name:mk923ca0cafdb7abb02570da09080d5be8735c7e Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0907 09:54:48.929667   14948 start.go:364] duration metric: took 48.103µs to acquireMachinesLock for "minikube"
I0907 09:54:48.929681   14948 start.go:96] Skipping create...Using existing machine configuration
I0907 09:54:48.929684   14948 fix.go:54] fixHost starting: 
I0907 09:54:48.929916   14948 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0907 09:54:48.949560   14948 fix.go:112] recreateIfNeeded on minikube: state=Running err=<nil>
W0907 09:54:48.949598   14948 fix.go:138] unexpected machine state, will restart: <nil>
I0907 09:54:48.952096   14948 out.go:177] * Updating the running docker "minikube" container ...
I0907 09:54:48.955059   14948 machine.go:93] provisionDockerMachine start ...
I0907 09:54:48.955131   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:48.974557   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:48.974815   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:48.974824   14948 main.go:141] libmachine: About to run SSH command:
hostname
I0907 09:54:49.104570   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0907 09:54:49.104607   14948 ubuntu.go:169] provisioning hostname "minikube"
I0907 09:54:49.104671   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:49.124799   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:49.125039   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:49.125046   14948 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0907 09:54:49.269326   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0907 09:54:49.269389   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:49.289780   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:49.290037   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:49.290053   14948 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0907 09:54:49.420263   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0907 09:54:49.420283   14948 ubuntu.go:175] set auth options {CertDir:/home/ubuntu/.minikube CaCertPath:/home/ubuntu/.minikube/certs/ca.pem CaPrivateKeyPath:/home/ubuntu/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/ubuntu/.minikube/machines/server.pem ServerKeyPath:/home/ubuntu/.minikube/machines/server-key.pem ClientKeyPath:/home/ubuntu/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/ubuntu/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/ubuntu/.minikube}
I0907 09:54:49.420311   14948 ubuntu.go:177] setting up certificates
I0907 09:54:49.420328   14948 provision.go:84] configureAuth start
I0907 09:54:49.420416   14948 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0907 09:54:49.440484   14948 provision.go:143] copyHostCerts
I0907 09:54:49.440521   14948 exec_runner.go:144] found /home/ubuntu/.minikube/ca.pem, removing ...
I0907 09:54:49.440537   14948 exec_runner.go:203] rm: /home/ubuntu/.minikube/ca.pem
I0907 09:54:49.440620   14948 exec_runner.go:151] cp: /home/ubuntu/.minikube/certs/ca.pem --> /home/ubuntu/.minikube/ca.pem (1078 bytes)
I0907 09:54:49.440777   14948 exec_runner.go:144] found /home/ubuntu/.minikube/cert.pem, removing ...
I0907 09:54:49.440777   14948 exec_runner.go:203] rm: /home/ubuntu/.minikube/cert.pem
I0907 09:54:49.440810   14948 exec_runner.go:151] cp: /home/ubuntu/.minikube/certs/cert.pem --> /home/ubuntu/.minikube/cert.pem (1119 bytes)
I0907 09:54:49.440897   14948 exec_runner.go:144] found /home/ubuntu/.minikube/key.pem, removing ...
I0907 09:54:49.440903   14948 exec_runner.go:203] rm: /home/ubuntu/.minikube/key.pem
I0907 09:54:49.440952   14948 exec_runner.go:151] cp: /home/ubuntu/.minikube/certs/key.pem --> /home/ubuntu/.minikube/key.pem (1679 bytes)
I0907 09:54:49.441015   14948 provision.go:117] generating server cert: /home/ubuntu/.minikube/machines/server.pem ca-key=/home/ubuntu/.minikube/certs/ca.pem private-key=/home/ubuntu/.minikube/certs/ca-key.pem org=ubuntu.minikube san=[127.0.0.1 192.168.49.2 localhost minikube]
I0907 09:54:49.754279   14948 provision.go:177] copyRemoteCerts
I0907 09:54:49.754352   14948 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0907 09:54:49.754427   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:49.774970   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:49.871544   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0907 09:54:49.900043   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1078 bytes)
I0907 09:54:49.928545   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/machines/server.pem --> /etc/docker/server.pem (1180 bytes)
I0907 09:54:49.957223   14948 provision.go:87] duration metric: took 536.878276ms to configureAuth
I0907 09:54:49.957237   14948 ubuntu.go:193] setting minikube options for container-runtime
I0907 09:54:49.957437   14948 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0907 09:54:49.957481   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:49.977895   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:49.978138   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:49.978148   14948 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0907 09:54:50.108240   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0907 09:54:50.108250   14948 ubuntu.go:71] root file system type: overlay
I0907 09:54:50.108364   14948 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0907 09:54:50.108449   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.129023   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:50.129261   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:50.129344   14948 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0907 09:54:50.275212   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0907 09:54:50.275270   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.295101   14948 main.go:141] libmachine: Using SSH client type: native
I0907 09:54:50.295424   14948 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bb20] 0x83e820 <nil>  [] 0s} 127.0.0.1 32768 <nil> <nil>}
I0907 09:54:50.295429   14948 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0907 09:54:50.432971   14948 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0907 09:54:50.432985   14948 machine.go:96] duration metric: took 1.477918725s to provisionDockerMachine
I0907 09:54:50.432992   14948 start.go:293] postStartSetup for "minikube" (driver="docker")
I0907 09:54:50.433004   14948 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0907 09:54:50.433077   14948 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0907 09:54:50.433132   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.453375   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:50.549990   14948 ssh_runner.go:195] Run: cat /etc/os-release
I0907 09:54:50.553743   14948 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0907 09:54:50.553762   14948 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0907 09:54:50.553771   14948 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0907 09:54:50.553777   14948 info.go:137] Remote host: Ubuntu 22.04.5 LTS
I0907 09:54:50.553786   14948 filesync.go:126] Scanning /home/ubuntu/.minikube/addons for local assets ...
I0907 09:54:50.553842   14948 filesync.go:126] Scanning /home/ubuntu/.minikube/files for local assets ...
I0907 09:54:50.553868   14948 start.go:296] duration metric: took 120.868609ms for postStartSetup
I0907 09:54:50.553908   14948 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0907 09:54:50.553965   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.574260   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:50.664078   14948 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0907 09:54:50.669161   14948 fix.go:56] duration metric: took 1.739469799s for fixHost
I0907 09:54:50.669171   14948 start.go:83] releasing machines lock for "minikube", held for 1.739497968s
I0907 09:54:50.669258   14948 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0907 09:54:50.689703   14948 ssh_runner.go:195] Run: cat /version.json
I0907 09:54:50.689713   14948 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0907 09:54:50.689729   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.689790   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:50.710451   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:50.711472   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:50.897216   14948 ssh_runner.go:195] Run: systemctl --version
I0907 09:54:50.902479   14948 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0907 09:54:50.907541   14948 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0907 09:54:50.929212   14948 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0907 09:54:50.929256   14948 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0907 09:54:50.939658   14948 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0907 09:54:50.939671   14948 start.go:495] detecting cgroup driver to use...
I0907 09:54:50.939697   14948 detect.go:190] detected "systemd" cgroup driver on host os
I0907 09:54:50.939795   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0907 09:54:50.958919   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I0907 09:54:50.970400   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0907 09:54:50.981734   14948 containerd.go:146] configuring containerd to use "systemd" as cgroup driver...
I0907 09:54:50.981767   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I0907 09:54:50.992859   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0907 09:54:51.004300   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0907 09:54:51.015508   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0907 09:54:51.026898   14948 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0907 09:54:51.037581   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0907 09:54:51.048976   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0907 09:54:51.060435   14948 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0907 09:54:51.071829   14948 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0907 09:54:51.081969   14948 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0907 09:54:51.091981   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:51.186047   14948 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0907 09:54:51.278710   14948 start.go:495] detecting cgroup driver to use...
I0907 09:54:51.278745   14948 detect.go:190] detected "systemd" cgroup driver on host os
I0907 09:54:51.279001   14948 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0907 09:54:51.294167   14948 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0907 09:54:51.294259   14948 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0907 09:54:51.309253   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0907 09:54:51.331301   14948 ssh_runner.go:195] Run: which cri-dockerd
I0907 09:54:51.335607   14948 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0907 09:54:51.347485   14948 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I0907 09:54:51.372300   14948 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0907 09:54:51.478308   14948 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0907 09:54:51.575547   14948 docker.go:587] configuring docker to use "systemd" as cgroup driver...
I0907 09:54:51.575639   14948 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I0907 09:54:51.600234   14948 ssh_runner.go:195] Run: sudo systemctl reset-failed docker
I0907 09:54:51.614013   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:51.715855   14948 ssh_runner.go:195] Run: sudo systemctl restart docker
I0907 09:54:52.722023   14948 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1.006132332s)
I0907 09:54:52.722080   14948 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0907 09:54:52.735513   14948 ssh_runner.go:195] Run: sudo systemctl stop cri-docker.socket
I0907 09:54:52.753050   14948 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0907 09:54:52.765939   14948 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0907 09:54:52.849240   14948 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0907 09:54:52.930743   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:53.015486   14948 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0907 09:54:53.039931   14948 ssh_runner.go:195] Run: sudo systemctl reset-failed cri-docker.service
I0907 09:54:53.053167   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:53.137709   14948 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0907 09:54:53.217197   14948 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0907 09:54:53.230662   14948 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0907 09:54:53.230708   14948 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0907 09:54:53.234720   14948 start.go:563] Will wait 60s for crictl version
I0907 09:54:53.234759   14948 ssh_runner.go:195] Run: which crictl
I0907 09:54:53.238702   14948 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0907 09:54:53.279392   14948 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  28.1.1
RuntimeApiVersion:  v1
I0907 09:54:53.279471   14948 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0907 09:54:53.307097   14948 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0907 09:54:53.337587   14948 out.go:235] * Preparing Kubernetes v1.33.1 on Docker 28.1.1 ...
I0907 09:54:53.337712   14948 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0907 09:54:53.358188   14948 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0907 09:54:53.363122   14948 kubeadm.go:875] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0907 09:54:53.363214   14948 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0907 09:54:53.363268   14948 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0907 09:54:53.386683   14948 docker.go:702] Got preloaded images: -- stdout --
registry.k8s.io/kube-scheduler:v1.33.1
registry.k8s.io/kube-apiserver:v1.33.1
registry.k8s.io/kube-controller-manager:v1.33.1
registry.k8s.io/kube-proxy:v1.33.1
registry.k8s.io/etcd:3.5.21-0
registry.k8s.io/coredns/coredns:v1.12.0
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0907 09:54:53.386699   14948 docker.go:632] Images already preloaded, skipping extraction
I0907 09:54:53.386743   14948 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0907 09:54:53.409211   14948 docker.go:702] Got preloaded images: -- stdout --
registry.k8s.io/kube-apiserver:v1.33.1
registry.k8s.io/kube-controller-manager:v1.33.1
registry.k8s.io/kube-scheduler:v1.33.1
registry.k8s.io/kube-proxy:v1.33.1
registry.k8s.io/etcd:3.5.21-0
registry.k8s.io/coredns/coredns:v1.12.0
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0907 09:54:53.409224   14948 cache_images.go:84] Images are preloaded, skipping loading
I0907 09:54:53.409236   14948 kubeadm.go:926] updating node { 192.168.49.2 8443 v1.33.1 docker true true} ...
I0907 09:54:53.409333   14948 kubeadm.go:938] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.33.1/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2

[Install]
 config:
{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0907 09:54:53.409386   14948 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0907 09:54:53.462197   14948 cni.go:84] Creating CNI manager for ""
I0907 09:54:53.462216   14948 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0907 09:54:53.462227   14948 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0907 09:54:53.462263   14948 kubeadm.go:189] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.33.1 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0907 09:54:53.462390   14948 kubeadm.go:195] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    - name: "node-ip"
      value: "192.168.49.2"
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    - name: "enable-admission-plugins"
      value: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    - name: "allocate-node-cidrs"
      value: "true"
    - name: "leader-elect"
      value: "false"
scheduler:
  extraArgs:
    - name: "leader-elect"
      value: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      - name: "proxy-refresh-interval"
        value: "70000"
kubernetesVersion: v1.33.1
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0907 09:54:53.462486   14948 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.33.1
I0907 09:54:53.473515   14948 binaries.go:44] Found k8s binaries, skipping transfer
I0907 09:54:53.473558   14948 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0907 09:54:53.483610   14948 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I0907 09:54:53.504500   14948 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0907 09:54:53.524717   14948 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2285 bytes)
I0907 09:54:53.545192   14948 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0907 09:54:53.549158   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:53.633649   14948 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0907 09:54:54.101841   14948 certs.go:68] Setting up /home/ubuntu/.minikube/profiles/minikube for IP: 192.168.49.2
I0907 09:54:54.101852   14948 certs.go:194] generating shared ca certs ...
I0907 09:54:54.101868   14948 certs.go:226] acquiring lock for ca certs: {Name:mk54be389229da646426b42cde5e43fe51d50235 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0907 09:54:54.102023   14948 certs.go:235] skipping valid "minikubeCA" ca cert: /home/ubuntu/.minikube/ca.key
I0907 09:54:54.102079   14948 certs.go:235] skipping valid "proxyClientCA" ca cert: /home/ubuntu/.minikube/proxy-client-ca.key
I0907 09:54:54.102089   14948 certs.go:256] generating profile certs ...
I0907 09:54:54.102188   14948 certs.go:359] skipping valid signed profile cert regeneration for "minikube-user": /home/ubuntu/.minikube/profiles/minikube/client.key
I0907 09:54:54.102250   14948 certs.go:359] skipping valid signed profile cert regeneration for "minikube": /home/ubuntu/.minikube/profiles/minikube/apiserver.key.7fb57e3c
I0907 09:54:54.102302   14948 certs.go:359] skipping valid signed profile cert regeneration for "aggregator": /home/ubuntu/.minikube/profiles/minikube/proxy-client.key
I0907 09:54:54.102462   14948 certs.go:484] found cert: /home/ubuntu/.minikube/certs/ca-key.pem (1675 bytes)
I0907 09:54:54.102500   14948 certs.go:484] found cert: /home/ubuntu/.minikube/certs/ca.pem (1078 bytes)
I0907 09:54:54.102526   14948 certs.go:484] found cert: /home/ubuntu/.minikube/certs/cert.pem (1119 bytes)
I0907 09:54:54.102550   14948 certs.go:484] found cert: /home/ubuntu/.minikube/certs/key.pem (1679 bytes)
I0907 09:54:54.104700   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0907 09:54:54.134228   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0907 09:54:54.163265   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0907 09:54:54.191467   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0907 09:54:54.219741   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0907 09:54:54.247936   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0907 09:54:54.275966   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0907 09:54:54.304130   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0907 09:54:54.331827   14948 ssh_runner.go:362] scp /home/ubuntu/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0907 09:54:54.360288   14948 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0907 09:54:54.381076   14948 ssh_runner.go:195] Run: openssl version
I0907 09:54:54.387086   14948 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0907 09:54:54.398285   14948 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0907 09:54:54.402372   14948 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Sep  4 20:16 /usr/share/ca-certificates/minikubeCA.pem
I0907 09:54:54.402436   14948 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0907 09:54:54.410160   14948 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0907 09:54:54.420384   14948 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0907 09:54:54.424411   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0907 09:54:54.432124   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0907 09:54:54.439583   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0907 09:54:54.446962   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0907 09:54:54.454332   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0907 09:54:54.461857   14948 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0907 09:54:54.469047   14948 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:3900 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/ubuntu:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0907 09:54:54.469144   14948 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0907 09:54:54.490553   14948 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0907 09:54:54.501373   14948 kubeadm.go:408] found existing configuration files, will attempt cluster restart
I0907 09:54:54.501381   14948 kubeadm.go:589] restartPrimaryControlPlane start ...
I0907 09:54:54.501438   14948 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0907 09:54:54.511579   14948 kubeadm.go:130] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0907 09:54:54.512108   14948 kubeconfig.go:125] found "minikube" server: "https://192.168.49.2:8443"
I0907 09:54:54.513585   14948 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0907 09:54:54.523765   14948 kubeadm.go:626] The running cluster does not require reconfiguration: 192.168.49.2
I0907 09:54:54.523782   14948 kubeadm.go:593] duration metric: took 22.396477ms to restartPrimaryControlPlane
I0907 09:54:54.523792   14948 kubeadm.go:394] duration metric: took 54.759848ms to StartCluster
I0907 09:54:54.523805   14948 settings.go:142] acquiring lock: {Name:mk258534599bdb5598e04e5075c71f19dc4dcb51 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0907 09:54:54.523865   14948 settings.go:150] Updating kubeconfig:  /home/ubuntu/.kube/config
I0907 09:54:54.524490   14948 lock.go:35] WriteFile acquiring /home/ubuntu/.kube/config: {Name:mkc2dc10c32db64677e63d0b927f8be22de50f2a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0907 09:54:54.524722   14948 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}
I0907 09:54:54.524807   14948 addons.go:511] enable addons start: toEnable=map[ambassador:false amd-gpu-device-plugin:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I0907 09:54:54.524888   14948 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0907 09:54:54.524902   14948 addons.go:238] Setting addon storage-provisioner=true in "minikube"
W0907 09:54:54.524909   14948 addons.go:247] addon storage-provisioner should already be in state true
I0907 09:54:54.524910   14948 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0907 09:54:54.524934   14948 host.go:66] Checking if "minikube" exists ...
I0907 09:54:54.524935   14948 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0907 09:54:54.524943   14948 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0907 09:54:54.525184   14948 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0907 09:54:54.525321   14948 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0907 09:54:54.527525   14948 out.go:177] * Verifying Kubernetes components...
I0907 09:54:54.530310   14948 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0907 09:54:54.548541   14948 addons.go:238] Setting addon default-storageclass=true in "minikube"
W0907 09:54:54.548552   14948 addons.go:247] addon default-storageclass should already be in state true
I0907 09:54:54.548575   14948 host.go:66] Checking if "minikube" exists ...
I0907 09:54:54.548937   14948 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0907 09:54:54.550049   14948 out.go:177]   - Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0907 09:54:54.552251   14948 addons.go:435] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0907 09:54:54.552261   14948 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0907 09:54:54.552319   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:54.576556   14948 addons.go:435] installing /etc/kubernetes/addons/storageclass.yaml
I0907 09:54:54.576569   14948 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0907 09:54:54.576637   14948 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0907 09:54:54.588826   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:54.601668   14948 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32768 SSHKeyPath:/home/ubuntu/.minikube/machines/minikube/id_rsa Username:docker}
I0907 09:54:54.628543   14948 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0907 09:54:54.695067   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0907 09:54:54.707111   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0907 09:54:54.850838   14948 api_server.go:52] waiting for apiserver process to appear ...
W0907 09:54:54.850894   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:54.850921   14948 retry.go:31] will retry after 207.804893ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0907 09:54:54.850979   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:54.850989   14948 retry.go:31] will retry after 129.938463ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:54.851017   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:54.981111   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:54:55.047267   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.047304   14948 retry.go:31] will retry after 274.769117ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.059535   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:54:55.124237   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.124259   14948 retry.go:31] will retry after 554.209333ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.322596   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0907 09:54:55.351276   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0907 09:54:55.387809   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.387832   14948 retry.go:31] will retry after 585.879706ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.679281   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:54:55.745275   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.745298   14948 retry.go:31] will retry after 569.865468ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:55.851672   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:55.974655   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:54:56.039306   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:56.039328   14948 retry.go:31] will retry after 814.656004ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:56.315875   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0907 09:54:56.351545   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0907 09:54:56.384050   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:56.384098   14948 retry.go:31] will retry after 781.375739ms: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:56.851808   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:56.854459   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:54:56.918506   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:56.918529   14948 retry.go:31] will retry after 1.644046736s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:57.165902   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:54:57.231111   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:57.231142   14948 retry.go:31] will retry after 1.828362851s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:57.351499   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:57.851683   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:58.352064   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:58.562894   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:54:58.630282   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:58.630331   14948 retry.go:31] will retry after 1.412832544s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:58.851903   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:59.060044   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:54:59.124190   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:59.124210   14948 retry.go:31] will retry after 2.030501962s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:54:59.351539   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:54:59.851912   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:00.043876   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:55:00.110950   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:00.110979   14948 retry.go:31] will retry after 3.542089054s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:00.351459   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:00.851650   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:01.154889   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:55:01.220708   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:01.220733   14948 retry.go:31] will retry after 4.049721021s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:01.351037   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:01.851778   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:02.351196   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:02.851797   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:03.352087   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:03.653362   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:55:03.719270   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:03.719294   14948 retry.go:31] will retry after 5.07217127s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:03.851650   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:04.351508   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:04.851950   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:05.271222   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:55:05.337274   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:05.337296   14948 retry.go:31] will retry after 6.005935712s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:05.351486   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:05.851142   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:06.351440   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:06.851668   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:07.351030   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:07.851201   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:08.351264   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:08.792365   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
I0907 09:55:08.851183   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0907 09:55:08.858304   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:08.858321   14948 retry.go:31] will retry after 9.152121715s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:09.351130   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:09.851692   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:10.351752   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:10.851184   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:11.343474   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
I0907 09:55:11.351194   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0907 09:55:11.411208   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:11.411230   14948 retry.go:31] will retry after 5.007758025s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:11.851666   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:12.351732   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:12.851713   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:13.351125   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:13.851674   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:14.351677   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:14.851671   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:15.352034   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:15.851093   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:16.351004   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:16.419747   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:55:16.487155   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:16.487177   14948 retry.go:31] will retry after 11.212697523s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:16.851743   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:17.351646   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:17.851571   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:18.011583   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:55:18.077297   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:18.077320   14948 retry.go:31] will retry after 9.933624086s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:18.351826   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:18.851299   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:19.351901   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:19.851176   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:20.351078   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:20.851187   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:21.351482   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:21.851129   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:22.351907   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:22.851433   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:23.352525   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:23.851799   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:24.351520   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:24.850981   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:25.351517   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:25.851156   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:26.351113   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:26.851137   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:27.351107   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:27.700150   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:55:27.764657   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:27.764677   14948 retry.go:31] will retry after 20.143548667s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:27.851940   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:28.011504   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:55:28.075364   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:28.075384   14948 retry.go:31] will retry after 7.458724137s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:28.351817   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:28.851903   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:29.351038   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:29.851884   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:30.351524   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:30.851658   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:31.351821   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:31.851146   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:32.351112   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:32.851954   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:33.351346   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:33.851833   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:34.351993   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:34.851619   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:35.351612   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:35.534697   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:55:35.599885   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:35.599905   14948 retry.go:31] will retry after 25.99041563s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:35.851245   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:36.351888   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:36.851643   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:37.351340   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:37.852000   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:38.351201   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:38.851631   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:39.351907   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:39.851341   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:40.351805   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:40.851512   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:41.351890   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:41.851960   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:42.351143   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:42.851288   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:43.351141   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:43.851940   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:44.351145   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:44.851803   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:45.352063   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:45.851079   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:46.351025   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:46.852101   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:47.351108   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:47.851133   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:47.908429   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:55:47.972131   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:47.972153   14948 retry.go:31] will retry after 31.886646333s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:55:48.351710   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:48.851429   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:49.351129   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:49.851809   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:50.351114   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:50.851182   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:51.351182   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:51.851506   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:52.351323   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:52.851151   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:53.351129   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:53.851036   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:54.351134   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:54.851673   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:55:54.895152   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:55:54.895217   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:55:54.919584   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:55:54.919669   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:55:54.944167   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:55:54.944228   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:55:54.967913   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:55:54.968006   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:55:54.991168   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:55:54.991290   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:55:55.015971   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:55:55.016091   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:55:55.039081   14948 logs.go:282] 0 containers: []
W0907 09:55:55.039087   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:55:55.039133   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:55:55.067993   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:55:55.068033   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:55:55.068043   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:55:55.125067   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:55:55.125087   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:55:55.201793   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:55:55.190143   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.192048   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.193612   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.195468   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.197284   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:55:55.190143   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.192048   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.193612   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.195468   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:55.197284   13565 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:55:55.201823   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:55:55.201835   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:55:55.230127   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:55:55.230144   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:55:55.258817   14948 logs.go:123] Gathering logs for container status ...
I0907 09:55:55.258835   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:55:55.324469   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:55:55.324507   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:55:55.340475   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:55:55.340513   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:55:55.423289   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:55:55.423309   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:55:55.461271   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:55:55.461287   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:55:55.491995   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:55:55.492014   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:55:55.517514   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:55:55.517530   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:55:55.560099   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:55:55.560132   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:55:55.612045   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:55:55.612065   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:55:58.138676   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:55:58.152088   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:55:58.174093   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:55:58.174144   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:55:58.195785   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:55:58.195823   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:55:58.216979   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:55:58.217027   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:55:58.238166   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:55:58.238225   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:55:58.258960   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:55:58.259014   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:55:58.280279   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:55:58.280328   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:55:58.301126   14948 logs.go:282] 0 containers: []
W0907 09:55:58.301139   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:55:58.301182   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:55:58.322190   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:55:58.322210   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:55:58.322219   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:55:58.353957   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:55:58.353972   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:55:58.383731   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:55:58.383746   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:55:58.408509   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:55:58.408523   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:55:58.448441   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:55:58.448458   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:55:58.500929   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:55:58.500948   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:55:58.525066   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:55:58.525073   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:55:58.572996   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:55:58.573012   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:55:58.647884   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:55:58.636185   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.637977   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.639744   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.641632   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.643241   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:55:58.636185   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.637977   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.639744   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.641632   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:55:58.643241   13832 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:55:58.647896   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:55:58.647907   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:55:58.727970   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:55:58.727988   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:55:58.754656   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:55:58.754671   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:55:58.781290   14948 logs.go:123] Gathering logs for container status ...
I0907 09:55:58.781303   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:55:58.826015   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:55:58.826032   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:01.341877   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:01.355623   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:01.377619   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:01.377678   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:01.399727   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:01.399774   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:01.421103   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:01.421159   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:01.442785   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:01.442860   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:01.464694   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:01.464754   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:01.486268   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:01.486331   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:01.508441   14948 logs.go:282] 0 containers: []
W0907 09:56:01.508462   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:01.508516   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:01.531035   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:01.531052   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:01.531063   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0907 09:56:01.591557   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:56:01.605347   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:01.592385   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.594661   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.596461   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.598224   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.600145   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:01.592385   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.594661   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.596461   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.598224   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:01.600145   13981 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:01.605358   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:01.605369   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
W0907 09:56:01.666560   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:56:01.666580   14948 retry.go:31] will retry after 42.497360255s: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
I0907 09:56:01.718866   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:01.718886   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:01.770755   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:01.770774   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:01.796766   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:01.796791   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:01.845570   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:01.845592   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:01.879752   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:01.879769   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:01.905683   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:01.905700   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:01.935915   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:01.935932   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:01.962554   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:01.962571   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:02.004377   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:02.004425   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:02.033046   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:02.033064   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:02.080361   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:02.080379   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:04.595555   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:04.608964   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:04.631595   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:04.631673   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:04.654372   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:04.654462   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:04.675842   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:04.675907   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:04.697176   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:04.697214   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:04.718271   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:04.718342   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:04.739143   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:04.739215   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:04.759508   14948 logs.go:282] 0 containers: []
W0907 09:56:04.759529   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:04.759564   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:04.780850   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:04.780875   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:04.780880   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:04.806412   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:04.806428   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:04.860243   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:04.860269   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:04.885443   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:04.885461   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:04.912146   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:04.912162   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:04.958560   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:04.958584   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:05.010934   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:05.010957   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:05.084883   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:05.073521   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.075285   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.077027   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.078718   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.080504   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:05.073521   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.075285   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.077027   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.078718   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:05.080504   14245 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:05.084896   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:05.084909   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:05.117605   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:05.117627   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:05.148920   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:05.148936   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:05.174868   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:05.174883   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:05.216640   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:05.216659   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:05.231645   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:05.231659   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:07.817308   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:07.831384   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:07.852975   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:07.853022   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:07.873733   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:07.873783   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:07.894492   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:07.894543   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:07.915072   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:07.915119   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:07.935093   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:07.935139   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:07.955880   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:07.955934   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:07.976445   14948 logs.go:282] 0 containers: []
W0907 09:56:07.976457   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:07.976506   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:07.997597   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:07.997617   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:07.997626   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:08.041847   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:08.041860   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:08.092007   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:08.092021   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:08.164395   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:08.153306   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.154981   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.156807   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.158520   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.160175   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:08.153306   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.154981   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.156807   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.158520   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:08.160175   14422 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:08.164426   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:08.164434   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:08.189274   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:08.189286   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:08.242489   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:08.242503   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:08.265361   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:08.265396   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:08.291989   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:08.292001   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:08.305344   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:08.305354   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:08.383849   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:08.383867   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:08.416422   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:08.416438   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:08.442146   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:08.442159   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:08.471904   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:08.471917   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:11.015331   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:11.029693   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:11.051355   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:11.051431   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:11.071797   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:11.071854   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:11.092310   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:11.092340   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:11.112938   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:11.112993   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:11.134022   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:11.134059   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:11.154849   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:11.154904   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:11.175815   14948 logs.go:282] 0 containers: []
W0907 09:56:11.175828   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:11.175865   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:11.196782   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:11.196802   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:11.196811   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:11.224232   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:11.224243   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:11.268490   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:11.268510   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:11.321088   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:11.321102   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:11.398670   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:11.386911   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.388797   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.390569   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.392260   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.393946   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:11.386911   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.388797   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.390569   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.392260   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:11.393946   14630 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:11.398682   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:11.398686   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:11.428980   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:11.428998   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:11.454629   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:11.454645   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:11.495528   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:11.495544   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:11.510148   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:11.510159   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:11.586932   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:11.586946   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:11.622084   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:11.622097   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:11.646987   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:11.647000   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:11.696817   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:11.696831   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:14.222599   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:14.236482   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:14.259074   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:14.259125   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:14.280361   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:14.280435   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:14.302207   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:14.302250   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:14.324812   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:14.324854   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:14.347168   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:14.347208   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:14.374623   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:14.374724   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:14.400603   14948 logs.go:282] 0 containers: []
W0907 09:56:14.400618   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:14.400695   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:14.423535   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:14.423558   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:14.423568   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:14.460046   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:14.460061   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:14.492489   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:14.492504   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:14.520768   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:14.520786   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:14.565950   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:14.565970   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:14.624089   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:14.624108   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:14.650198   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:14.650214   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:14.702750   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:14.702761   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:14.775482   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:14.763748   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.765515   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.767192   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.768894   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.770633   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:14.763748   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.765515   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.767192   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.768894   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:14.770633   14897 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:14.775494   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:14.775502   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:14.801069   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:14.801074   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:14.828048   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:14.828062   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:14.873106   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:14.873125   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:14.887243   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:14.887254   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:17.474001   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:17.487822   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:17.509744   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:17.509784   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:17.529788   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:17.529834   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:17.550650   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:17.550701   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:17.570466   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:17.570514   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:17.591088   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:17.591132   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:17.610991   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:17.611043   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:17.629808   14948 logs.go:282] 0 containers: []
W0907 09:56:17.629821   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:17.629857   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:17.649471   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:17.649488   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:17.649497   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:17.663576   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:17.663587   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:17.735697   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:17.724215   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.726184   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.727954   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.729693   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.731347   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:17.724215   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.726184   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.727954   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.729693   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:17.731347   15054 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:17.735702   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:17.735724   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:17.817171   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:17.817188   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:17.842992   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:17.843007   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:17.883221   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:17.883237   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:17.929417   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:17.929440   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:17.978880   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:17.978891   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:18.012613   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:18.012625   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:18.037514   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:18.037516   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:18.067822   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:18.067837   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:18.127076   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:18.127094   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:18.151855   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:18.151874   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:19.859031   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml
W0907 09:56:19.924614   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0907 09:56:19.924743   14948 out.go:270] ! Enabling 'storage-provisioner' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storage-provisioner.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storage-provisioner.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0907 09:56:20.679762   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:20.693550   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:20.715666   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:20.715720   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:20.736866   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:20.736925   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:20.757933   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:20.757987   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:20.779854   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:20.779903   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:20.801432   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:20.801480   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:20.822223   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:20.822275   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:20.842606   14948 logs.go:282] 0 containers: []
W0907 09:56:20.842617   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:20.842647   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:20.863886   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:20.863909   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:20.863919   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:20.891692   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:20.891721   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:20.936989   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:20.937005   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:20.985350   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:20.985364   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:20.998842   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:20.998853   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:21.081309   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:21.081323   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:21.119140   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:21.119159   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:21.148072   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:21.148084   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:21.191082   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:21.191098   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:21.243494   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:21.243509   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:21.266755   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:21.266767   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:21.339022   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:21.327468   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.329266   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.331140   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.332904   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.334699   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:21.327468   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.329266   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.331140   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.332904   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:21.334699   15340 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:21.339066   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:21.339080   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:21.365333   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:21.365350   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:23.895149   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:23.908703   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:23.930211   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:23.930260   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:23.951288   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:23.951353   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:23.972460   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:23.972513   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:23.993776   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:23.993827   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:24.015356   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:24.015433   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:24.037165   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:24.037226   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:24.056722   14948 logs.go:282] 0 containers: []
W0907 09:56:24.056733   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:24.056756   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:24.076935   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:24.076955   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:24.076964   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:24.102215   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:24.102247   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:24.157683   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:24.157702   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:24.182772   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:24.182788   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:24.227691   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:24.227697   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:24.279845   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:24.279861   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:24.294039   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:24.294051   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:24.379083   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:24.379101   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:24.404981   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:24.404996   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:24.434069   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:24.434087   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:24.476359   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:24.476373   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:24.502911   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:24.502923   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:24.574577   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:24.563047   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.565001   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.566766   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.568509   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.570336   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:24.563047   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.565001   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.566766   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.568509   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:24.570336   15554 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:24.574596   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:24.574606   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:27.107525   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:27.120784   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:27.144039   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:27.144089   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:27.164491   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:27.164537   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:27.184829   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:27.184873   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:27.205448   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:27.205491   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:27.226595   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:27.226643   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:27.247962   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:27.248016   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:27.271502   14948 logs.go:282] 0 containers: []
W0907 09:56:27.271519   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:27.271569   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:27.292786   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:27.292809   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:27.292819   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:27.340726   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:27.340743   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:27.412486   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:27.401348   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.403137   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.404868   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.406562   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.408283   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:27.401348   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.403137   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.404868   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.406562   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:27.408283   15694 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:27.412498   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:27.412509   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:27.494947   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:27.494963   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:27.526058   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:27.526075   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:27.551203   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:27.551208   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:27.574972   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:27.574986   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:27.622745   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:27.622759   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:27.637095   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:27.637118   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:27.669796   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:27.669809   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:27.694843   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:27.694857   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:27.734816   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:27.734831   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:27.787912   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:27.787925   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:30.318449   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:30.332350   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:30.354611   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:30.354660   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:30.375194   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:30.375249   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:30.396162   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:30.396207   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:30.416216   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:30.416254   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:30.436961   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:30.437015   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:30.458057   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:30.458118   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:30.478312   14948 logs.go:282] 0 containers: []
W0907 09:56:30.478325   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:30.478342   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:30.499351   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:30.499375   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:30.499380   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:30.571485   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:30.560052   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.561873   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.563577   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.565278   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.567154   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:30.560052   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.561873   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.563577   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.565278   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:30.567154   15888 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:30.571497   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:30.571508   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:30.596638   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:30.596651   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:30.639033   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:30.639048   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:30.663458   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:30.663458   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:30.692208   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:30.692220   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:30.742941   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:30.742951   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:30.823074   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:30.823103   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:30.856751   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:30.856766   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:30.882107   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:30.882125   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:30.911808   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:30.911823   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:30.963291   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:30.963305   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:31.007737   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:31.007753   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:33.523656   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:33.537702   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:33.559723   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:33.559782   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:33.580849   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:33.580910   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:33.602539   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:33.602590   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:33.624522   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:33.624585   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:33.646125   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:33.646187   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:33.667973   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:33.668024   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:33.689153   14948 logs.go:282] 0 containers: []
W0907 09:56:33.689167   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:33.689212   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:33.710743   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:33.710764   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:33.710777   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:33.756707   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:33.756725   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:33.785006   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:33.785022   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:33.799148   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:33.799160   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:33.829840   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:33.829857   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:33.857360   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:33.857378   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:33.913560   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:33.913582   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:33.938485   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:33.938502   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:33.982487   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:33.982506   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:34.030657   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:34.030676   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:34.104161   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:34.092544   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.094354   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.096051   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.097824   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.099479   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:34.092544   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.094354   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.096051   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.097824   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:34.099479   16172 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:34.104171   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:34.104187   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:34.184886   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:34.184910   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:34.218958   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:34.218975   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:36.746339   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:36.760274   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:36.782173   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:36.782226   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:36.803242   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:36.803288   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:36.823091   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:36.823137   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:36.845436   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:36.845490   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:36.867020   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:36.867076   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:36.889699   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:36.889753   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:36.911505   14948 logs.go:282] 0 containers: []
W0907 09:56:36.911517   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:36.911559   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:36.932981   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:36.933003   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:36.933012   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:36.957250   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:36.957262   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:36.996998   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:36.997010   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:37.048806   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:37.048824   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:37.072742   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:37.072754   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:37.086608   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:37.086615   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:37.165597   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:37.165616   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:37.197022   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:37.197037   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:37.221782   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:37.221797   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:37.250551   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:37.250565   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:37.295872   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:37.295888   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:37.343932   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:37.343949   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:37.415833   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:37.404509   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.406314   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.408050   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.409835   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.411575   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:37.404509   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.406314   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.408050   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.409835   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:37.411575   16394 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:37.415845   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:37.415855   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:39.950483   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:39.963818   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:39.985370   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:39.985425   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:40.005432   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:40.005484   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:40.025332   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:40.025371   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:40.045727   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:40.045772   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:40.066446   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:40.066507   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:40.088390   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:40.088457   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:40.108793   14948 logs.go:282] 0 containers: []
W0907 09:56:40.108793   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:40.108841   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:40.129942   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:40.129965   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:40.129974   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:40.154692   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:40.154704   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:40.196408   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:40.196431   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:40.220279   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:40.220292   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:40.265326   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:40.265337   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:40.350600   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:40.350616   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:40.381266   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:40.381285   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:40.405126   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:40.405131   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:40.457882   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:40.457899   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:40.487101   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:40.487114   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:40.535824   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:40.535838   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:40.549263   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:40.549275   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:40.621957   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:40.609574   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.611294   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.613263   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.615233   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.617095   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:40.609574   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.611294   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.613263   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.615233   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:40.617095   16599 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:40.621972   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:40.621983   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:43.158904   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:43.172548   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:43.194065   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:43.194110   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:43.215502   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:43.215547   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:43.235789   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:43.235830   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:43.255861   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:43.255898   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:43.277002   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:43.277048   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:43.297551   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:43.297604   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:43.316824   14948 logs.go:282] 0 containers: []
W0907 09:56:43.316835   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:43.316877   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:43.338547   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:43.338571   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:43.338580   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:43.382612   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:43.382628   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:43.396600   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:43.396612   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:43.467915   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:43.456693   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.458519   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.460155   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.461922   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.463609   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:43.456693   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.458519   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.460155   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.461922   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:43.463609   16747 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:43.467921   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:43.467932   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:43.556186   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:43.556202   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:43.582625   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:43.582636   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:43.614473   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:43.614489   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:43.659055   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:43.659086   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:43.711020   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:43.711034   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:43.733493   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:43.733504   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:43.783154   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:43.783173   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:43.814971   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:43.814984   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:43.839936   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:43.839952   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:44.164234   14948 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml
W0907 09:56:44.228017   14948 addons.go:461] apply failed, will retry: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
W0907 09:56:44.228115   14948 out.go:270] ! Enabling 'default-storageclass' returned an error: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply --force -f /etc/kubernetes/addons/storageclass.yaml: Process exited with status 1
stdout:

stderr:
error: error validating "/etc/kubernetes/addons/storageclass.yaml": error validating data: failed to download openapi: Get "https://localhost:8443/openapi/v2?timeout=32s": dial tcp [::1]:8443: connect: connection refused; if you choose to ignore these errors, turn validation off with --validate=false
]
I0907 09:56:44.230227   14948 out.go:177] * Enabled addons: 
I0907 09:56:44.232747   14948 addons.go:514] duration metric: took 1m49.707946597s for enable addons: enabled=[]
I0907 09:56:46.367918   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:46.381826   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:46.403785   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:46.403849   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:46.425955   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:46.426019   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:46.447791   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:46.447857   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:46.469730   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:46.469787   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:46.491752   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:46.491827   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:46.513897   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:46.513943   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:46.532934   14948 logs.go:282] 0 containers: []
W0907 09:56:46.532944   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:46.532986   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:46.553787   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:46.553807   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:46.553817   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:46.603857   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:46.603873   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:46.653555   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:46.653571   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:46.724440   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:46.713224   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.714993   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.716717   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.718459   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.720133   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:46.713224   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.714993   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.716717   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.718459   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:46.720133   16971 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:46.724450   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:46.724462   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:46.758692   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:46.758706   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:46.789165   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:46.789179   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:46.814262   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:46.814273   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:46.855104   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:46.855119   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:46.882764   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:46.882777   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:46.896498   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:46.896509   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:46.979051   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:46.979067   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:47.005225   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:47.005252   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:47.057917   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:47.057933   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:49.582515   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:49.595817   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:49.618255   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:49.618311   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:49.640439   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:49.641103   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:49.662512   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:49.662552   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:49.683416   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:49.683478   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:49.706236   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:49.706333   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:49.727175   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:49.727225   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:49.747279   14948 logs.go:282] 0 containers: []
W0907 09:56:49.747288   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:49.747330   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:49.768496   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:49.768508   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:49.768527   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:49.819645   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:49.819657   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:49.833682   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:49.833693   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:49.905588   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:49.893724   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.895484   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.897183   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.898916   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.900684   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:49.893724   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.895484   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.897183   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.898916   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:49.900684   17174 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:49.905613   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:49.905623   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:49.991899   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:49.991915   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:50.024940   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:50.024959   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:50.050772   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:50.050789   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:50.075302   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:50.075316   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:50.117463   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:50.117477   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:50.146362   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:50.146375   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:50.196293   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:50.196308   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:50.219952   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:50.219967   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:50.246029   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:50.246042   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:52.792328   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:52.805785   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:52.827154   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:52.827192   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:52.847323   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:52.847362   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:52.868014   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:52.868063   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:52.889367   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:52.889434   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:52.910256   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:52.910288   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:52.931281   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:52.931318   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:52.951174   14948 logs.go:282] 0 containers: []
W0907 09:56:52.951185   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:52.951210   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:52.971654   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:52.971680   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:52.971689   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:53.015916   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:53.015931   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:53.067386   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:53.067410   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:53.081158   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:53.081170   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:53.152425   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:53.140915   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.142675   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.144508   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.146264   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.147957   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:53.140915   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.142675   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.144508   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.146264   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:53.147957   17386 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:53.152436   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:53.152446   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:53.182831   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:53.182845   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:53.207253   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:53.207267   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:53.249091   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:53.249103   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:53.298801   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:53.298815   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:53.326509   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:53.326522   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:53.412105   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:53.412127   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:53.445525   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:53.445541   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:53.470659   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:53.470673   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:55.994201   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:56.007663   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:56.029951   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:56.030007   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:56.051215   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:56.051275   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:56.072318   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:56.072381   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:56.093064   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:56.093111   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:56.113661   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:56.113710   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:56.133860   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:56.133910   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:56.154376   14948 logs.go:282] 0 containers: []
W0907 09:56:56.154387   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:56.154454   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:56.175291   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:56.175312   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:56.175321   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:56.224273   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:56.224287   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:56.238218   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:56.238229   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:56.270983   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:56.270999   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:56.295676   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:56.295688   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:56:56.320636   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:56.320650   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:56.364377   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:56.364408   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:56.390479   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:56.390490   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:56.418179   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:56.418194   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:56.490222   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:56.478839   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.480563   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.482287   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.483962   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.485640   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:56.478839   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.480563   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.482287   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.483962   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:56.485640   17637 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:56.490235   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:56.490247   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:56.572643   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:56.572659   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:56.602932   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:56.602945   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:56.655664   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:56.655677   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:59.207232   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:56:59.221121   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:56:59.242967   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:56:59.243022   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:56:59.263517   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:56:59.263558   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:56:59.285122   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:56:59.285172   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:56:59.306238   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:56:59.306287   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:56:59.326855   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:56:59.326904   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:56:59.347670   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:56:59.347731   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:56:59.369135   14948 logs.go:282] 0 containers: []
W0907 09:56:59.369148   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:56:59.369188   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:56:59.391124   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:56:59.391151   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:56:59.391159   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:56:59.414862   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:56:59.414877   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:56:59.441039   14948 logs.go:123] Gathering logs for container status ...
I0907 09:56:59.441051   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:56:59.487744   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:56:59.487759   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:56:59.501326   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:56:59.501337   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:56:59.581437   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:56:59.581453   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:56:59.614615   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:56:59.614631   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:56:59.638917   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:56:59.638929   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:56:59.680008   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:56:59.680021   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:56:59.733342   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:56:59.733355   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:56:59.783791   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:56:59.783804   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:56:59.855634   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:56:59.844448   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.846192   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.847913   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.849747   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.851437   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:56:59.844448   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.846192   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.847913   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.849747   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:56:59.851437   17870 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:56:59.855658   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:56:59.855668   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:56:59.885181   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:56:59.885194   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:02.410510   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:02.423508   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:02.444827   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:02.444865   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:02.464995   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:02.465047   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:02.485651   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:02.485706   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:02.506760   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:02.506810   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:02.526963   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:02.527014   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:02.547630   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:02.547684   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:02.567823   14948 logs.go:282] 0 containers: []
W0907 09:57:02.567832   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:02.567872   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:02.588107   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:02.588128   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:57:02.588137   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:57:02.636384   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:02.636411   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:02.650088   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:57:02.650100   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:57:02.733054   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:57:02.733070   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:57:02.758703   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:57:02.758712   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:02.784017   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:57:02.784032   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:57:02.839176   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:57:02.839197   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:57:02.863815   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:02.863832   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:57:02.936126   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:57:02.924369   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.926153   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.927865   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.929585   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.931242   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:57:02.924369   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.926153   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.927865   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.929585   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:02.931242   18052 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:57:02.936139   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:57:02.936152   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:57:02.969882   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:57:02.969898   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:57:02.999536   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:57:02.999550   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:57:03.041899   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:03.041913   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:03.068955   14948 logs.go:123] Gathering logs for container status ...
I0907 09:57:03.068968   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:57:05.617563   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:05.631578   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:05.653363   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:05.653432   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:05.674250   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:05.674299   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:05.694769   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:05.694819   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:05.716111   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:05.716161   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:05.736756   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:05.736795   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:05.758035   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:05.758095   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:05.778345   14948 logs.go:282] 0 containers: []
W0907 09:57:05.778357   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:05.778385   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:05.798920   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:05.798944   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:57:05.798953   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:57:05.847418   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:05.847430   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:05.861017   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:57:05.861027   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:57:05.939206   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:57:05.939222   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:57:05.971279   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:57:05.971299   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:57:05.996094   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:57:05.996107   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:57:06.025697   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:57:06.025712   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:06.051587   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:57:06.051609   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:57:06.092307   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:06.092318   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:57:06.165811   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:57:06.154614   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.156353   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.157992   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.159751   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.161458   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:57:06.154614   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.156353   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.157992   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.159751   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:06.161458   18278 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:57:06.165818   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:57:06.165831   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:57:06.217629   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:57:06.217644   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:57:06.242018   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:06.242032   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:06.269666   14948 logs.go:123] Gathering logs for container status ...
I0907 09:57:06.269678   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:57:08.813940   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:08.827578   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:08.849288   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:08.849338   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:08.869436   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:08.869484   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:08.891005   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:08.891036   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:08.911103   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:08.911152   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:08.932119   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:08.932169   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:08.952919   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:08.952964   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:08.973503   14948 logs.go:282] 0 containers: []
W0907 09:57:08.973515   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:08.973552   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:08.994913   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:08.994935   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:57:08.994946   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:57:09.024314   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:57:09.024331   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:09.049364   14948 logs.go:123] Gathering logs for container status ...
I0907 09:57:09.049378   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:57:09.094451   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:57:09.094468   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:57:09.128204   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:57:09.128224   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:57:09.156018   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:57:09.156035   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:57:09.196462   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:57:09.196479   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:57:09.249133   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:57:09.249149   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:57:09.273155   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:09.273169   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:09.300122   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:57:09.300137   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:57:09.351473   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:09.351488   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:09.365486   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:09.365497   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:57:09.435644   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:57:09.424321   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.426063   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.427813   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.429560   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.431303   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:57:09.424321   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.426063   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.427813   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.429560   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:09.431303   18511 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:57:09.435655   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:57:09.435667   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:57:12.016591   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:12.030365   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:12.052360   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:12.052440   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:12.073290   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:12.073342   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:12.094578   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:12.094635   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:12.117181   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:12.117243   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:12.142107   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:12.142229   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:12.163858   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:12.163915   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:12.185055   14948 logs.go:282] 0 containers: []
W0907 09:57:12.185066   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:12.185110   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:12.206862   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:12.206885   14948 logs.go:123] Gathering logs for container status ...
I0907 09:57:12.206891   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:57:12.251210   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:12.251225   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:12.265020   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:57:12.265032   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:57:12.346493   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:57:12.346511   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:57:12.372680   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:57:12.372693   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:57:12.402527   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:57:12.402541   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:12.428292   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:57:12.428307   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:57:12.468410   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:12.468428   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:12.496583   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:57:12.496598   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:57:12.543931   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:12.543950   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:57:12.615039   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:57:12.603764   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.605511   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.607283   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.609044   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.610699   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:57:12.603764   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.605511   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.607283   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.609044   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:12.610699   18701 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:57:12.615051   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:57:12.615061   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:57:12.647511   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:57:12.647525   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:57:12.701275   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:57:12.701292   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:57:15.226185   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:15.239889   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:15.261672   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:15.261728   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:15.282325   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:15.282370   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:15.302665   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:15.302717   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:15.323437   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:15.323491   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:15.344152   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:15.344202   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:15.364059   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:15.364096   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:15.384173   14948 logs.go:282] 0 containers: []
W0907 09:57:15.384177   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:15.384227   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:15.405658   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:15.405678   14948 logs.go:123] Gathering logs for kubelet ...
I0907 09:57:15.405678   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0907 09:57:15.454163   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:15.454178   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
W0907 09:57:15.526852   14948 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:57:15.515027   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.516806   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.518504   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.520205   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.521924   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0907 09:57:15.515027   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.516806   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.518504   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.520205   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:57:15.521924   18852 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0907 09:57:15.526861   14948 logs.go:123] Gathering logs for kube-apiserver [a23e8ab04cc1] ...
I0907 09:57:15.526862   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a23e8ab04cc1"
I0907 09:57:15.607699   14948 logs.go:123] Gathering logs for coredns [e62821075391] ...
I0907 09:57:15.607718   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e62821075391"
I0907 09:57:15.633425   14948 logs.go:123] Gathering logs for kube-controller-manager [bb0600659c0c] ...
I0907 09:57:15.633438   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bb0600659c0c"
I0907 09:57:15.673083   14948 logs.go:123] Gathering logs for storage-provisioner [95009bf07b15] ...
I0907 09:57:15.673099   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 95009bf07b15"
I0907 09:57:15.724225   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:15.724241   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:15.752685   14948 logs.go:123] Gathering logs for container status ...
I0907 09:57:15.752696   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0907 09:57:15.797699   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:15.797715   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:15.811996   14948 logs.go:123] Gathering logs for etcd [76c81f7a621b] ...
I0907 09:57:15.812008   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 76c81f7a621b"
I0907 09:57:15.852379   14948 logs.go:123] Gathering logs for kube-scheduler [c103ae31ab43] ...
I0907 09:57:15.852456   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c103ae31ab43"
I0907 09:57:15.887411   14948 logs.go:123] Gathering logs for kube-proxy [99e27e140654] ...
I0907 09:57:15.887430   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 99e27e140654"
I0907 09:57:15.918234   14948 logs.go:123] Gathering logs for storage-provisioner [91ecaf4f23da] ...
I0907 09:57:15.918249   14948 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 91ecaf4f23da"
I0907 09:57:18.445857   14948 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0907 09:57:18.459918   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0907 09:57:18.482165   14948 logs.go:282] 1 containers: [a23e8ab04cc1]
I0907 09:57:18.482228   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0907 09:57:18.503916   14948 logs.go:282] 1 containers: [76c81f7a621b]
I0907 09:57:18.503973   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0907 09:57:18.525893   14948 logs.go:282] 1 containers: [e62821075391]
I0907 09:57:18.525941   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0907 09:57:18.547539   14948 logs.go:282] 1 containers: [c103ae31ab43]
I0907 09:57:18.547600   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0907 09:57:18.569008   14948 logs.go:282] 1 containers: [99e27e140654]
I0907 09:57:18.569058   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0907 09:57:18.591591   14948 logs.go:282] 1 containers: [bb0600659c0c]
I0907 09:57:18.591670   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0907 09:57:18.613378   14948 logs.go:282] 0 containers: []
W0907 09:57:18.613395   14948 logs.go:284] No container was found matching "kindnet"
I0907 09:57:18.613464   14948 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0907 09:57:18.634893   14948 logs.go:282] 2 containers: [95009bf07b15 91ecaf4f23da]
I0907 09:57:18.634929   14948 logs.go:123] Gathering logs for Docker ...
I0907 09:57:18.634939   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0907 09:57:18.662858   14948 logs.go:123] Gathering logs for dmesg ...
I0907 09:57:18.662872   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0907 09:57:18.676719   14948 logs.go:123] Gathering logs for describe nodes ...
I0907 09:57:18.676734   14948 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"


==> Docker <==
Sep 07 09:49:40 minikube cri-dockerd[1797]: time="2025-09-07T09:49:40Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Sep 07 09:49:40 minikube cri-dockerd[1797]: time="2025-09-07T09:49:40Z" level=info msg="Start cri-dockerd grpc backend"
Sep 07 09:49:40 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Sep 07 09:54:51 minikube systemd[1]: Stopping Docker Application Container Engine...
Sep 07 09:54:51 minikube dockerd[1483]: time="2025-09-07T09:54:51.198315962Z" level=info msg="Processing signal 'terminated'"
Sep 07 09:54:51 minikube dockerd[1483]: time="2025-09-07T09:54:51.200100199Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 07 09:54:51 minikube dockerd[1483]: time="2025-09-07T09:54:51.200573640Z" level=info msg="Daemon shutdown complete"
Sep 07 09:54:51 minikube dockerd[1483]: time="2025-09-07T09:54:51.200698211Z" level=info msg="stopping event stream following graceful shutdown" error="context canceled" module=libcontainerd namespace=plugins.moby
Sep 07 09:54:51 minikube systemd[1]: docker.service: Deactivated successfully.
Sep 07 09:54:51 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 07 09:54:51 minikube systemd[1]: docker.service: Consumed 1.714s CPU time.
Sep 07 09:54:51 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.326973032Z" level=info msg="Starting up"
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.327973222Z" level=info msg="OTEL tracing is not configured, using no-op tracer provider"
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.341763082Z" level=info msg="Creating a containerd client" address=/run/containerd/containerd.sock timeout=1m0s
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.357975215Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.391286486Z" level=info msg="Loading containers: start."
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.735586399Z" level=info msg="Processing signal 'terminated'"
Sep 07 09:54:51 minikube dockerd[11178]: time="2025-09-07T09:54:51.951376437Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint_count 477eff94e1814e8e8895e6764f5f89573c48dab100a161a04a329e1a6e23df06], retrying...."
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.004831968Z" level=info msg="Loading containers: done."
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.019341367Z" level=info msg="Docker daemon" commit=01f442b containerd-snapshotter=false storage-driver=overlay2 version=28.1.1
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.019443708Z" level=info msg="Initializing buildkit"
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.025062390Z" level=info msg="Completed buildkit initialization"
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.033374632Z" level=info msg="Daemon has completed initialization"
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.033535709Z" level=info msg="API listen on [::]:2376"
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.033547691Z" level=info msg="API listen on /var/run/docker.sock"
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.034774135Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 07 09:54:52 minikube dockerd[11178]: time="2025-09-07T09:54:52.035158984Z" level=info msg="Daemon shutdown complete"
Sep 07 09:54:52 minikube systemd[1]: docker.service: Deactivated successfully.
Sep 07 09:54:52 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 07 09:54:52 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.085326057Z" level=info msg="Starting up"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.086469982Z" level=info msg="OTEL tracing is not configured, using no-op tracer provider"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.098790475Z" level=info msg="Creating a containerd client" address=/run/containerd/containerd.sock timeout=1m0s
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.107321164Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.124162947Z" level=info msg="Loading containers: start."
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.637492807Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint_count 29b5fcb711a31aafc1793f7472b3252f6511bea85806753c5cfd25a9d9b992dd], retrying...."
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.688353348Z" level=info msg="Loading containers: done."
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.706522145Z" level=info msg="Docker daemon" commit=01f442b containerd-snapshotter=false storage-driver=overlay2 version=28.1.1
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.706611468Z" level=info msg="Initializing buildkit"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.712303128Z" level=info msg="Completed buildkit initialization"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.719825329Z" level=info msg="Daemon has completed initialization"
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.719941256Z" level=info msg="API listen on [::]:2376"
Sep 07 09:54:52 minikube systemd[1]: Started Docker Application Container Engine.
Sep 07 09:54:52 minikube dockerd[11532]: time="2025-09-07T09:54:52.719951020Z" level=info msg="API listen on /var/run/docker.sock"
Sep 07 09:54:52 minikube systemd[1]: Stopping CRI Interface for Docker Application Container Engine...
Sep 07 09:54:52 minikube systemd[1]: cri-docker.service: Deactivated successfully.
Sep 07 09:54:52 minikube systemd[1]: Stopped CRI Interface for Docker Application Container Engine.
Sep 07 09:54:53 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Start docker client with request timeout 0s"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Hairpin mode is set to hairpin-veth"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Loaded network plugin cni"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Docker cri networking managed by network plugin cni"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Setting cgroupDriver systemd"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Sep 07 09:54:53 minikube cri-dockerd[11860]: time="2025-09-07T09:54:53Z" level=info msg="Start cri-dockerd grpc backend"
Sep 07 09:54:53 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
95009bf07b159       6e38f40d628db       2 days ago          Exited              storage-provisioner       1                   1c06e599f683f       storage-provisioner
e62821075391f       1cf5f116067c6       2 days ago          Exited              coredns                   0                   cdf95058c758e       coredns-674b8bbfcf-hdwwh
99e27e1406549       b79c189b052cd       2 days ago          Exited              kube-proxy                0                   c16bf3f5c366b       kube-proxy-4stll
91ecaf4f23dae       6e38f40d628db       2 days ago          Exited              storage-provisioner       0                   1c06e599f683f       storage-provisioner
bb0600659c0c7       ef43894fa110c       2 days ago          Exited              kube-controller-manager   0                   7c05afd2d78ec       kube-controller-manager-minikube
c103ae31ab436       398c985c0d950       2 days ago          Exited              kube-scheduler            0                   9bb1447afac8b       kube-scheduler-minikube
a23e8ab04cc16       c6ab243b29f82       2 days ago          Exited              kube-apiserver            0                   cc59b2b0a6ce8       kube-apiserver-minikube
76c81f7a621b5       499038711c081       2 days ago          Exited              etcd                      0                   913a64311fe38       etcd-minikube


==> coredns [e62821075391] <==
maxprocs: Leaving GOMAXPROCS=4: CPU quota undefined
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 9e2996f8cb67ac53e0259ab1f8d615d07d1beb0bd07e6a1e39769c3bf486a905bb991cc47f8d2f14d0d3a90a87dfc625a0b4c524fed169d8158c40657c0694b1
CoreDNS-1.12.0
linux/amd64, go1.23.3, 51e11f1
[INFO] 127.0.0.1:42070 - 13921 "HINFO IN 4543923515637971398.4190643508798057464. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.00444451s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s


==> describe nodes <==
command /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" failed with error: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0907 09:59:57.086648   21779 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:59:57.088544   21779 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:59:57.090132   21779 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:59:57.091897   21779 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
E0907 09:59:57.093623   21779 memcache.go:265] "Unhandled Error" err="couldn't get current server API group list: Get \"https://localhost:8443/api?timeout=32s\": dial tcp [::1]:8443: connect: connection refused"
The connection to the server localhost:8443 was refused - did you specify the right host or port?


==> dmesg <==
[Sep 7 09:32] Cannot get hvm parameter CONSOLE_EVTCHN (18): -22!
[  +0.898665] cpu 0 spinlock event irq 53
[  +0.000000]   #2
[  +0.000000]   #3
[  +0.000000] cpu 1 spinlock event irq 69
[  +0.000000] cpu 2 spinlock event irq 70
[  +0.000000] cpu 3 spinlock event irq 71
[  +0.000000] acpi PNP0A03:00: fail to add MMCONFIG information, can't access extended configuration space under this bridge
[  +0.000000] * Found PM-Timer Bug on the chipset. Due to workarounds for a bug,
              * this clock source is slow. Consider trying other clock sources
[  +0.172348] Grant table initialized
[  +0.003617] Cannot get hvm parameter CONSOLE_EVTCHN (18): -22!
[  +0.269641] device-mapper: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.
[  +8.105326] kauditd_printk_skb: 118 callbacks suppressed


==> etcd [76c81f7a621b] <==
{"level":"info","ts":"2025-09-04T20:16:50.116944Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"4.289424ms"}
{"level":"info","ts":"2025-09-04T20:16:50.123068Z","caller":"etcdserver/raft.go:506","msg":"starting local member","local-member-id":"aec36adc501070cc","cluster-id":"fa54960ea34d58be"}
{"level":"info","ts":"2025-09-04T20:16:50.123757Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2025-09-04T20:16:50.123870Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 0"}
{"level":"info","ts":"2025-09-04T20:16:50.123886Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2025-09-04T20:16:50.123896Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2025-09-04T20:16:50.124020Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2025-09-04T20:16:50.129125Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2025-09-04T20:16:50.131668Z","caller":"mvcc/kvstore.go:425","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2025-09-04T20:16:50.132336Z","caller":"etcdserver/server.go:628","msg":"restore consistentIndex","index":0}
{"level":"info","ts":"2025-09-04T20:16:50.134733Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2025-09-04T20:16:50.137270Z","caller":"etcdserver/server.go:875","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.21","cluster-version":"to_be_decided"}
{"level":"info","ts":"2025-09-04T20:16:50.138081Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-09-04T20:16:50.138404Z","caller":"etcdserver/server.go:759","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2025-09-04T20:16:50.138464Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2025-09-04T20:16:50.139062Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2025-09-04T20:16:50.139169Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2025-09-04T20:16:50.141742Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2025-09-04T20:16:50.141992Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"],"added-peer-is-learner":false}
{"level":"info","ts":"2025-09-04T20:16:50.143572Z","caller":"embed/etcd.go:762","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2025-09-04T20:16:50.143753Z","caller":"embed/etcd.go:633","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-09-04T20:16:50.143787Z","caller":"embed/etcd.go:603","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-09-04T20:16:50.144342Z","caller":"embed/etcd.go:292","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2025-09-04T20:16:50.144532Z","caller":"embed/etcd.go:908","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2025-09-04T20:16:51.125418Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2025-09-04T20:16:51.125463Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2025-09-04T20:16:51.125481Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2025-09-04T20:16:51.125528Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2025-09-04T20:16:51.125574Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2025-09-04T20:16:51.125587Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2025-09-04T20:16:51.125597Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2025-09-04T20:16:51.127023Z","caller":"embed/serve.go:124","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-09-04T20:16:51.127817Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-09-04T20:16:51.128474Z","caller":"embed/serve.go:275","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.49.2:2379"}
{"level":"info","ts":"2025-09-04T20:16:51.128782Z","caller":"etcdserver/server.go:2697","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2025-09-04T20:16:51.126975Z","caller":"etcdserver/server.go:2144","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2025-09-04T20:16:51.129354Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2025-09-04T20:16:51.129382Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2025-09-04T20:16:51.129875Z","caller":"embed/serve.go:124","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-09-04T20:16:51.130455Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-09-04T20:16:51.131252Z","caller":"embed/serve.go:275","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2025-09-04T20:16:51.131660Z","caller":"membership/cluster.go:587","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2025-09-04T20:16:51.132013Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2025-09-04T20:16:51.132235Z","caller":"etcdserver/server.go:2721","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2025-09-04T20:26:51.292409Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":609}
{"level":"info","ts":"2025-09-04T20:26:51.298378Z","caller":"mvcc/kvstore_compaction.go:71","msg":"finished scheduled compaction","compact-revision":609,"took":"5.624905ms","hash":365820931,"current-db-size-bytes":1327104,"current-db-size":"1.3 MB","current-db-size-in-use-bytes":1327104,"current-db-size-in-use":"1.3 MB"}
{"level":"info","ts":"2025-09-04T20:26:51.298417Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":365820931,"revision":609,"compact-revision":-1}
{"level":"info","ts":"2025-09-04T20:31:51.297851Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":848}
{"level":"info","ts":"2025-09-04T20:31:51.300282Z","caller":"mvcc/kvstore_compaction.go:71","msg":"finished scheduled compaction","compact-revision":848,"took":"2.20219ms","hash":2281070311,"current-db-size-bytes":1327104,"current-db-size":"1.3 MB","current-db-size-in-use-bytes":897024,"current-db-size-in-use":"897 kB"}
{"level":"info","ts":"2025-09-04T20:31:51.300325Z","caller":"mvcc/hash.go:151","msg":"storing new hash","hash":2281070311,"revision":848,"compact-revision":609}
{"level":"info","ts":"2025-09-04T20:32:14.802185Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2025-09-04T20:32:14.802240Z","caller":"embed/etcd.go:408","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"info","ts":"2025-09-04T20:32:21.804548Z","caller":"etcdserver/server.go:1546","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"warn","ts":"2025-09-04T20:32:21.804670Z","caller":"embed/serve.go:235","msg":"stopping secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"warn","ts":"2025-09-04T20:32:21.804732Z","caller":"embed/serve.go:237","msg":"stopped secure grpc server due to error","error":"accept tcp 192.168.49.2:2379: use of closed network connection"}
{"level":"warn","ts":"2025-09-04T20:32:21.804648Z","caller":"embed/serve.go:235","msg":"stopping secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"warn","ts":"2025-09-04T20:32:21.804781Z","caller":"embed/serve.go:237","msg":"stopped secure grpc server due to error","error":"accept tcp 127.0.0.1:2379: use of closed network connection"}
{"level":"info","ts":"2025-09-04T20:32:21.806741Z","caller":"embed/etcd.go:613","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-09-04T20:32:21.806849Z","caller":"embed/etcd.go:618","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2025-09-04T20:32:21.806864Z","caller":"embed/etcd.go:410","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}


==> kernel <==
 09:59:57 up 27 min,  0 users,  load average: 0.12, 0.35, 0.28
Linux minikube 6.14.0-1012-aws #12~24.04.1-Ubuntu SMP Fri Aug 15 00:16:05 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.5 LTS"


==> kube-apiserver [a23e8ab04cc1] <==
W0904 20:32:20.171108       1 logging.go:55] [core] [Channel #34 SubChannel #35]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.177914       1 logging.go:55] [core] [Channel #127 SubChannel #128]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.180188       1 logging.go:55] [core] [Channel #52 SubChannel #53]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.253870       1 logging.go:55] [core] [Channel #10 SubChannel #11]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.266868       1 logging.go:55] [core] [Channel #172 SubChannel #173]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.300916       1 logging.go:55] [core] [Channel #37 SubChannel #38]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.310372       1 logging.go:55] [core] [Channel #112 SubChannel #113]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.321155       1 logging.go:55] [core] [Channel #169 SubChannel #170]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.339335       1 logging.go:55] [core] [Channel #148 SubChannel #149]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.400801       1 logging.go:55] [core] [Channel #64 SubChannel #65]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.403062       1 logging.go:55] [core] [Channel #58 SubChannel #59]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.406487       1 logging.go:55] [core] [Channel #166 SubChannel #167]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.433990       1 logging.go:55] [core] [Channel #88 SubChannel #89]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.472167       1 logging.go:55] [core] [Channel #139 SubChannel #140]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.595791       1 logging.go:55] [core] [Channel #19 SubChannel #20]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.607263       1 logging.go:55] [core] [Channel #145 SubChannel #146]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.632179       1 logging.go:55] [core] [Channel #49 SubChannel #50]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.715489       1 logging.go:55] [core] [Channel #175 SubChannel #176]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:20.725045       1 logging.go:55] [core] [Channel #73 SubChannel #74]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:22.946139       1 logging.go:55] [core] [Channel #25 SubChannel #26]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.021947       1 logging.go:55] [core] [Channel #115 SubChannel #116]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.121424       1 logging.go:55] [core] [Channel #22 SubChannel #23]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.282968       1 logging.go:55] [core] [Channel #163 SubChannel #164]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.393799       1 logging.go:55] [core] [Channel #79 SubChannel #80]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.466388       1 logging.go:55] [core] [Channel #184 SubChannel #185]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.508986       1 logging.go:55] [core] [Channel #85 SubChannel #86]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.529687       1 logging.go:55] [core] [Channel #103 SubChannel #104]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.591557       1 logging.go:55] [core] [Channel #82 SubChannel #83]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.672409       1 logging.go:55] [core] [Channel #94 SubChannel #95]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.725980       1 logging.go:55] [core] [Channel #88 SubChannel #89]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.744031       1 logging.go:55] [core] [Channel #91 SubChannel #92]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.747596       1 logging.go:55] [core] [Channel #1 SubChannel #3]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.764815       1 logging.go:55] [core] [Channel #136 SubChannel #137]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.766204       1 logging.go:55] [core] [Channel #121 SubChannel #122]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.780974       1 logging.go:55] [core] [Channel #67 SubChannel #68]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.789444       1 logging.go:55] [core] [Channel #70 SubChannel #71]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.793755       1 logging.go:55] [core] [Channel #40 SubChannel #41]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.841306       1 logging.go:55] [core] [Channel #160 SubChannel #161]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.855017       1 logging.go:55] [core] [Channel #100 SubChannel #101]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.876548       1 logging.go:55] [core] [Channel #2 SubChannel #4]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.882017       1 logging.go:55] [core] [Channel #31 SubChannel #32]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.945990       1 logging.go:55] [core] [Channel #76 SubChannel #77]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.954892       1 logging.go:55] [core] [Channel #97 SubChannel #98]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.958296       1 logging.go:55] [core] [Channel #145 SubChannel #146]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:23.990990       1 logging.go:55] [core] [Channel #166 SubChannel #167]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.023408       1 logging.go:55] [core] [Channel #19 SubChannel #20]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.076623       1 logging.go:55] [core] [Channel #52 SubChannel #53]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.083992       1 logging.go:55] [core] [Channel #130 SubChannel #131]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.099759       1 logging.go:55] [core] [Channel #109 SubChannel #110]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.112412       1 logging.go:55] [core] [Channel #124 SubChannel #125]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.149659       1 logging.go:55] [core] [Channel #46 SubChannel #47]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.151011       1 logging.go:55] [core] [Channel #151 SubChannel #152]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.183802       1 logging.go:55] [core] [Channel #127 SubChannel #128]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.199218       1 logging.go:55] [core] [Channel #106 SubChannel #107]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.242284       1 logging.go:55] [core] [Channel #169 SubChannel #170]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.265959       1 logging.go:55] [core] [Channel #172 SubChannel #173]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.330011       1 logging.go:55] [core] [Channel #148 SubChannel #149]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.343053       1 logging.go:55] [core] [Channel #181 SubChannel #182]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.396388       1 logging.go:55] [core] [Channel #154 SubChannel #155]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"
W0904 20:32:24.433645       1 logging.go:55] [core] [Channel #61 SubChannel #62]grpc: addrConn.createTransport failed to connect to {Addr: "127.0.0.1:2379", ServerName: "127.0.0.1:2379", }. Err: connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:2379: connect: connection refused"


==> kube-controller-manager [bb0600659c0c] <==
I0904 20:16:58.891377       1 node_lifecycle_controller.go:453] "Sending events to api server" logger="node-lifecycle-controller"
I0904 20:16:58.891421       1 node_lifecycle_controller.go:464] "Starting node controller" logger="node-lifecycle-controller"
I0904 20:16:58.891429       1 shared_informer.go:350] "Waiting for caches to sync" controller="taint"
I0904 20:16:59.042653       1 controllermanager.go:778] "Started controller" controller="ttl-controller"
I0904 20:16:59.042743       1 ttl_controller.go:127] "Starting TTL controller" logger="ttl-controller"
I0904 20:16:59.042759       1 shared_informer.go:350] "Waiting for caches to sync" controller="TTL"
I0904 20:16:59.050281       1 shared_informer.go:350] "Waiting for caches to sync" controller="resource quota"
I0904 20:16:59.066895       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrapproving"
I0904 20:16:59.070934       1 shared_informer.go:350] "Waiting for caches to sync" controller="garbage collector"
I0904 20:16:59.092963       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kubelet-serving"
I0904 20:16:59.092996       1 shared_informer.go:357] "Caches are synced" controller="service-cidr-controller"
I0904 20:16:59.093075       1 shared_informer.go:357] "Caches are synced" controller="ClusterRoleAggregator"
I0904 20:16:59.093408       1 shared_informer.go:357] "Caches are synced" controller="validatingadmissionpolicy-status"
I0904 20:16:59.093560       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kubelet-client"
I0904 20:16:59.095305       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kube-apiserver-client"
I0904 20:16:59.096672       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-legacy-unknown"
I0904 20:16:59.100462       1 shared_informer.go:357] "Caches are synced" controller="expand"
I0904 20:16:59.107788       1 shared_informer.go:357] "Caches are synced" controller="PV protection"
I0904 20:16:59.143932       1 shared_informer.go:357] "Caches are synced" controller="endpoint_slice_mirroring"
I0904 20:16:59.160140       1 shared_informer.go:357] "Caches are synced" controller="deployment"
I0904 20:16:59.174787       1 shared_informer.go:357] "Caches are synced" controller="PVC protection"
I0904 20:16:59.185105       1 shared_informer.go:357] "Caches are synced" controller="legacy-service-account-token-cleaner"
I0904 20:16:59.192076       1 shared_informer.go:357] "Caches are synced" controller="endpoint"
I0904 20:16:59.192120       1 shared_informer.go:357] "Caches are synced" controller="stateful set"
I0904 20:16:59.192126       1 shared_informer.go:357] "Caches are synced" controller="disruption"
I0904 20:16:59.192208       1 shared_informer.go:357] "Caches are synced" controller="HPA"
I0904 20:16:59.193449       1 shared_informer.go:357] "Caches are synced" controller="ReplicaSet"
I0904 20:16:59.193499       1 shared_informer.go:357] "Caches are synced" controller="ReplicationController"
I0904 20:16:59.194655       1 shared_informer.go:357] "Caches are synced" controller="ephemeral"
I0904 20:16:59.242928       1 shared_informer.go:357] "Caches are synced" controller="cronjob"
I0904 20:16:59.242973       1 shared_informer.go:357] "Caches are synced" controller="TTL after finished"
I0904 20:16:59.254363       1 shared_informer.go:357] "Caches are synced" controller="job"
I0904 20:16:59.314719       1 shared_informer.go:357] "Caches are synced" controller="crt configmap"
I0904 20:16:59.344165       1 shared_informer.go:357] "Caches are synced" controller="bootstrap_signer"
I0904 20:16:59.350418       1 shared_informer.go:357] "Caches are synced" controller="resource quota"
I0904 20:16:59.397765       1 shared_informer.go:357] "Caches are synced" controller="resource quota"
I0904 20:16:59.399468       1 actual_state_of_world.go:541] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0904 20:16:59.400320       1 shared_informer.go:357] "Caches are synced" controller="node"
I0904 20:16:59.400527       1 range_allocator.go:177] "Sending events to api server" logger="node-ipam-controller"
I0904 20:16:59.400556       1 range_allocator.go:183] "Starting range CIDR allocator" logger="node-ipam-controller"
I0904 20:16:59.400566       1 shared_informer.go:350] "Waiting for caches to sync" controller="cidrallocator"
I0904 20:16:59.400574       1 shared_informer.go:357] "Caches are synced" controller="cidrallocator"
I0904 20:16:59.408587       1 range_allocator.go:428] "Set node PodCIDR" logger="node-ipam-controller" node="minikube" podCIDRs=["10.244.0.0/24"]
I0904 20:16:59.443272       1 shared_informer.go:357] "Caches are synced" controller="service account"
I0904 20:16:59.443328       1 shared_informer.go:357] "Caches are synced" controller="taint-eviction-controller"
I0904 20:16:59.443403       1 shared_informer.go:357] "Caches are synced" controller="TTL"
I0904 20:16:59.443415       1 shared_informer.go:357] "Caches are synced" controller="attach detach"
I0904 20:16:59.446892       1 shared_informer.go:357] "Caches are synced" controller="endpoint_slice"
I0904 20:16:59.448109       1 shared_informer.go:357] "Caches are synced" controller="namespace"
I0904 20:16:59.492363       1 shared_informer.go:357] "Caches are synced" controller="persistent volume"
I0904 20:16:59.492428       1 shared_informer.go:357] "Caches are synced" controller="taint"
I0904 20:16:59.492495       1 node_lifecycle_controller.go:1221] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0904 20:16:59.492557       1 node_lifecycle_controller.go:873] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="minikube"
I0904 20:16:59.492724       1 shared_informer.go:357] "Caches are synced" controller="GC"
I0904 20:16:59.492744       1 shared_informer.go:357] "Caches are synced" controller="daemon sets"
I0904 20:16:59.493024       1 node_lifecycle_controller.go:1067] "Controller detected that zone is now in new state" logger="node-lifecycle-controller" zone="" newState="Normal"
I0904 20:16:59.871462       1 shared_informer.go:357] "Caches are synced" controller="garbage collector"
I0904 20:16:59.941974       1 shared_informer.go:357] "Caches are synced" controller="garbage collector"
I0904 20:16:59.942000       1 garbagecollector.go:154] "Garbage collector: all resource monitors have synced" logger="garbage-collector-controller"
I0904 20:16:59.942009       1 garbagecollector.go:157] "Proceeding to collect garbage" logger="garbage-collector-controller"


==> kube-proxy [99e27e140654] <==
I0904 20:17:01.032841       1 server_linux.go:63] "Using iptables proxy"
I0904 20:17:01.107610       1 server.go:715] "Successfully retrieved node IP(s)" IPs=["192.168.49.2"]
E0904 20:17:01.107716       1 server.go:245] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0904 20:17:01.157125       1 server.go:254] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0904 20:17:01.157207       1 server_linux.go:145] "Using iptables Proxier"
I0904 20:17:01.164778       1 proxier.go:243] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0904 20:17:01.171309       1 server.go:516] "Version info" version="v1.33.1"
I0904 20:17:01.172594       1 server.go:518] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0904 20:17:01.177522       1 config.go:199] "Starting service config controller"
I0904 20:17:01.177562       1 shared_informer.go:350] "Waiting for caches to sync" controller="service config"
I0904 20:17:01.179053       1 config.go:105] "Starting endpoint slice config controller"
I0904 20:17:01.179793       1 shared_informer.go:350] "Waiting for caches to sync" controller="endpoint slice config"
I0904 20:17:01.179448       1 config.go:440] "Starting serviceCIDR config controller"
I0904 20:17:01.179896       1 shared_informer.go:350] "Waiting for caches to sync" controller="serviceCIDR config"
I0904 20:17:01.179395       1 config.go:329] "Starting node config controller"
I0904 20:17:01.180022       1 shared_informer.go:350] "Waiting for caches to sync" controller="node config"
I0904 20:17:01.278586       1 shared_informer.go:357] "Caches are synced" controller="service config"
I0904 20:17:01.280824       1 shared_informer.go:357] "Caches are synced" controller="node config"
I0904 20:17:01.280853       1 shared_informer.go:357] "Caches are synced" controller="endpoint slice config"
I0904 20:17:01.280858       1 shared_informer.go:357] "Caches are synced" controller="serviceCIDR config"


==> kube-scheduler [c103ae31ab43] <==
I0904 20:16:50.752974       1 serving.go:386] Generated self-signed cert in-memory
W0904 20:16:52.424902       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0904 20:16:52.425763       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0904 20:16:52.425800       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0904 20:16:52.425820       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0904 20:16:52.454655       1 server.go:171] "Starting Kubernetes Scheduler" version="v1.33.1"
I0904 20:16:52.454683       1 server.go:173] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0904 20:16:52.456950       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0904 20:16:52.456992       1 shared_informer.go:350] "Waiting for caches to sync" controller="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0904 20:16:52.457230       1 secure_serving.go:211] Serving securely on 127.0.0.1:10259
I0904 20:16:52.457329       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E0904 20:16:52.459448       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: configmaps \"extension-apiserver-authentication\" is forbidden: User \"system:kube-scheduler\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\"" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0904 20:16:52.462228       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \"system:kube-scheduler\" cannot list resource \"poddisruptionbudgets\" in API group \"policy\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0904 20:16:52.462534       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0904 20:16:52.462661       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0904 20:16:52.462959       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicasets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0904 20:16:52.462960       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"storageclasses\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass"
E0904 20:16:52.463265       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"statefulsets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0904 20:16:52.463739       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: nodes is forbidden: User \"system:kube-scheduler\" cannot list resource \"nodes\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0904 20:16:52.464170       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"volumeattachments\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0904 20:16:52.464350       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csidrivers\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0904 20:16:52.464782       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicationcontrollers\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0904 20:16:52.464889       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumes\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0904 20:16:52.465005       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumeclaims\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0904 20:16:52.464806       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: pods is forbidden: User \"system:kube-scheduler\" cannot list resource \"pods\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0904 20:16:52.465179       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csinodes\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0904 20:16:52.465231       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot list resource \"services\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0904 20:16:53.322366       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: configmaps \"extension-apiserver-authentication\" is forbidden: User \"system:kube-scheduler\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\"" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0904 20:16:53.368331       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0904 20:16:53.395868       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"statefulsets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0904 20:16:53.549308       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: pods is forbidden: User \"system:kube-scheduler\" cannot list resource \"pods\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0904 20:16:53.692765       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumeclaims\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0904 20:16:53.697138       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csinodes\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0904 20:16:53.701750       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot list resource \"services\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0904 20:16:53.744577       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicasets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
I0904 20:16:56.057935       1 shared_informer.go:357] "Caches are synced" controller="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0904 20:32:14.812814       1 tlsconfig.go:258] "Shutting down DynamicServingCertificateController"
I0904 20:32:14.821338       1 secure_serving.go:259] Stopped listening on 127.0.0.1:10259
I0904 20:32:14.821510       1 configmap_cafile_content.go:226] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
E0904 20:32:14.858103       1 run.go:72] "command failed" err="finished without leader elect"


==> kubelet <==
Sep 07 09:59:52 minikube kubelet[21603]: I0907 09:59:52.649329   21603 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:52 minikube kubelet[21603]: I0907 09:59:52.649416   21603 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:52 minikube kubelet[21603]: I0907 09:59:52.649660   21603 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:52 minikube kubelet[21603]: E0907 09:59:52.649703   21603 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:52 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:52 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:53 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 816.
Sep 07 09:59:53 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:53 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:53 minikube kubelet[21621]: I0907 09:59:53.390974   21621 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:53 minikube kubelet[21621]: I0907 09:59:53.391043   21621 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:53 minikube kubelet[21621]: I0907 09:59:53.391275   21621 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:53 minikube kubelet[21621]: E0907 09:59:53.391327   21621 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:53 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:53 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 817.
Sep 07 09:59:54 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:54 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:54 minikube kubelet[21636]: I0907 09:59:54.149428   21636 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:54 minikube kubelet[21636]: I0907 09:59:54.149499   21636 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:54 minikube kubelet[21636]: I0907 09:59:54.149808   21636 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:54 minikube kubelet[21636]: E0907 09:59:54.150331   21636 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 818.
Sep 07 09:59:54 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:54 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:54 minikube kubelet[21647]: I0907 09:59:54.894679   21647 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:54 minikube kubelet[21647]: I0907 09:59:54.894761   21647 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:54 minikube kubelet[21647]: I0907 09:59:54.895025   21647 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:54 minikube kubelet[21647]: E0907 09:59:54.895069   21647 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:54 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:55 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 819.
Sep 07 09:59:55 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:55 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:55 minikube kubelet[21657]: I0907 09:59:55.649439   21657 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:55 minikube kubelet[21657]: I0907 09:59:55.649503   21657 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:55 minikube kubelet[21657]: I0907 09:59:55.649718   21657 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:55 minikube kubelet[21657]: E0907 09:59:55.649761   21657 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:55 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:55 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:56 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 820.
Sep 07 09:59:56 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:56 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:56 minikube kubelet[21667]: I0907 09:59:56.405344   21667 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:56 minikube kubelet[21667]: I0907 09:59:56.405437   21667 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:56 minikube kubelet[21667]: I0907 09:59:56.405688   21667 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:56 minikube kubelet[21667]: E0907 09:59:56.405736   21667 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:56 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:56 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Sep 07 09:59:57 minikube systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 821.
Sep 07 09:59:57 minikube systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
Sep 07 09:59:57 minikube systemd[1]: Started kubelet: The Kubernetes Node Agent.
Sep 07 09:59:57 minikube kubelet[21785]: I0907 09:59:57.141978   21785 server.go:530] "Kubelet version" kubeletVersion="v1.33.1"
Sep 07 09:59:57 minikube kubelet[21785]: I0907 09:59:57.142040   21785 server.go:532] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 07 09:59:57 minikube kubelet[21785]: I0907 09:59:57.142283   21785 server.go:956] "Client rotation is on, will bootstrap in background"
Sep 07 09:59:57 minikube kubelet[21785]: E0907 09:59:57.142330   21785 run.go:72] "command failed" err="failed to run Kubelet: unable to load bootstrap kubeconfig: stat /etc/kubernetes/bootstrap-kubelet.conf: no such file or directory"
Sep 07 09:59:57 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=1/FAILURE
Sep 07 09:59:57 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.


==> storage-provisioner [91ecaf4f23da] <==
I0904 20:17:00.809135       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0904 20:17:30.813576       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout


==> storage-provisioner [95009bf07b15] <==
W0904 20:31:14.553568       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:14.557854       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:16.561489       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:16.565434       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:18.568805       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:18.574545       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:20.577748       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:20.581686       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:22.585392       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:22.591746       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:24.594794       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:24.598894       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:26.602361       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:26.605781       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:28.608769       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:28.612524       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:30.615607       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:30.619100       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:32.622631       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:32.626507       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:34.630060       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:34.633806       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:36.636798       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:36.642134       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:38.645673       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:38.649563       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:40.652813       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:40.657230       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:42.659854       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:42.665317       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:44.668882       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:44.672404       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:46.675750       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:46.679656       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:48.682622       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:48.686501       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:50.689174       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:50.692890       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:52.696337       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:52.700217       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:54.704084       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:54.709769       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:56.713196       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:56.717098       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:58.719881       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:31:58.723502       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:00.726857       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:00.733231       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:02.736517       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:02.740372       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:04.743846       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:04.747577       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:06.750855       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:06.756544       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:08.759184       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:08.764442       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:10.768017       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:10.771676       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:12.775078       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice
W0904 20:32:12.778870       1 warnings.go:70] v1 Endpoints is deprecated in v1.33+; use discovery.k8s.io/v1 EndpointSlice

